---
title: "Final Project"
author: "Berta Canal & Adam Olivares"
date: "2023-11-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(glmnet)
library(sigmoid)
library(caret)
library(MASS)
library(ggplot2)
library(dplyr)
library(tidyverse) # multipurpose package developped by Posit
library(rstanarm) # Easy estimation of standard models with Bayesian methods 
#library(bayestestR) # Functions to analyze posterior distributions generated by rstranarm
library(mombf) # Bayesian model selection and Bayesian model averaging
library(ltm) #correlation for binary outcome
library(Hmisc) #describe
set.seed(1234)
```


```{r}
darwin <- read.csv("DARWIN.csv", sep = ",", header = TRUE)
darwin <- darwin[,-1]
#darwin_Y <- as.numeric(darwin$class %in% c("P")) #generate a dichotomous variable
#darwin[,"class"] <- darwin_Y
#darwin <- data.frame(scale(darwin,center=TRUE))
```

```{r}
darwin_Y <- as.numeric(darwin$class %in% c("P")) #generate a dichotomous variable
#darwin_Y <- as.numeric(darwin$class)
darwin_x <- data.frame(darwin[, !colnames(darwin) %in% c("ID", "class")])
# darwin_x <- scale(darwin_x)
```

## Data exploration

Count the number of instances of each class (dependent variable). No clas imbalance:

```{r}
ggplot(darwin, aes(x = class)) +
  geom_bar() 
```

low variance features

```{r}
var_test_results <- function(x_data, cutoff){
  
    coef <- sapply(x_data, function(x) var(x)) #variance
    status <- ifelse(coef >= cutoff, sprintf("above_%s", cutoff), sprintf("below_%s", cutoff))
    data.frame(
    item = names(coef),
    variance = matrix(round(coef,3)),
    status = as.character(status), row.names = c(names(coef))
  )  
}
var_test <- var_test_results(darwin_x, 0.2)

names_list_var_below_cutoff <- row.names(var_test[var_test$variance <= 0.2, ])
```

```{r}
var_test %>% count(status)
```
correlation between x features. 
```{r}
correlations <- cor(darwin_x)
highCorr <- findCorrelation(correlations, cutoff = .95, names = TRUE, exact = FALSE)  
print(highCorr)
#new_darwin_x <- darwin_x[,!(names(darwin_x) %in% highCorr)]# eliminate by correlation
#names_list_var_below_cutoff
#new_darwin_x <- darwin_x[,!(names(darwin_x) %in% names_list_var_below_cutoff)]# eliminate by variance
```

To deal with the problem of high correlation among features, we can transform the most correlated pair of tests in a new set of variables (differences and means) bewteen the variables present in both sets:

drop variables from all tests that we know from theory that have linear dependency ("total_time", "mean_gmrt):

```{r}
drop_darwin_x <- darwin_x %>% dplyr::select(-starts_with(c("total_time", "mean_gmrt")))
```

Get the names of the metrics measured in all tests:

```{r}
# Extract substrings excluding numbers using gsub to obtain unique column names
unique_variable_names <- unique(
  
  gsub("\\d", "", names(drop_darwin_x))
)
unique_variable_names

```

Function to transform pairs of tests by taking variables and computing their differences and means to deal with colinearity:

```{r}
transformed_darwin_generator <- function(input_df, unique_variable_names, list_of_pairs, diff = TRUE) {
  stopifnot(is.logical(diff), !is.na(diff)) #warning if diff not boolean
  

  rowmean_diff_df_gen <- function(test_pairs) {
    test_1 <- test_pairs[1] #element 1 of the vector with a pair
    test_2 <- test_pairs[2] #element 2 of the vector with a pair
  
    n_obs_individual <- nrow(input_df) #observations
    num_variable_names <- length(unique_variable_names) #number of unique metrics evaluated across experiments

  
    output_df_1 <- data.frame(matrix(ncol = num_variable_names, nrow = n_obs_individual))
    colnames(output_df_1) <- unique_variable_names #create an empty dataframe
  
    output_df_2 <- data.frame(matrix(ncol = num_variable_names, nrow = n_obs_individual))
    colnames(output_df_2) <- unique_variable_names #create an empty dataframe
  
  # compute averages 
    for (variable_name in unique_variable_names){
      nm_vector <- paste0(variable_name, "", c(test_1, test_2))
      output_df_1[variable_name] <- rowMeans(input_df[nm_vector], na.rm = TRUE)
    }
    
    mean_names_test_1_2 <- paste0("mean_", unique_variable_names, "_" ,test_1, "_", test_2)
    colnames(output_df_1) <- mean_names_test_1_2
  
    # compute differences
    if (diff == TRUE){
      for (variable_name in unique_variable_names){
        nm_vector1 <- paste0(variable_name, "", c(test_1))
        nm_vector2 <- paste0(variable_name, "", c(test_2))
        output_df_2[variable_name] <- input_df[nm_vector1] - input_df[nm_vector2]
      }
    
  
    diff_names_test_1_2 <- paste0("diff_", unique_variable_names, "_" ,test_1, "_", test_2)
    colnames(output_df_2) <- diff_names_test_1_2
    
    # merge both metrics
    
    output_df <- cbind(output_df_1, output_df_2)
    return(output_df)
    
    } else {
      output_df <- output_df_1
      return(output_df)
    }
  
    # merge both metrics
  
    output_df <- cbind(output_df_1, output_df_2)
  
    return(output_df)
  }
  ### now create the final dataset with the function we created inside this function

  #iterate over list of pairs to generate new transformed columns
  mean_diff_darwin_x <- data.frame() #empty dataframe to pour values into

    for (pair in list_of_pairs) {
      output <- rowmean_diff_df_gen(pair)
      mean_diff_darwin_x <- data.frame(append(output, mean_diff_darwin_x))
    }

  # merge with original dataset darwin_x and remove processed columns 

  complete_vector <-c()

  for (element in unlist(list_of_pairs)){
    string_vector <- paste0(unique_variable_names, element)
    complete_vector <- append(complete_vector, string_vector)
  }

input_df <- input_df %>% dplyr::select(-ends_with(complete_vector))

mean_diff_darwin_x <- cbind(mean_diff_darwin_x, input_df)

return(mean_diff_darwin_x) #return output

}

```

#Create a list with vectors including the pairs of tests that contain very similar information which should be transformed into means and differences

```{r}
list_of_pairs <- list(c(2,3), c(4,5), c(8,9), c(10,12), c(11,13), c(15,16))

functional_darwin <- transformed_darwin_generator(drop_darwin_x, unique_variable_names, list_of_pairs, diff = TRUE)
```

PART OF THE CODE TO RUN LOGISTIC REGRESSIONS WITH THE VARIABLES OF EACH TEST IN MOMBF AND SELECT POTENTIALLY INFORMATIVE VARIABLES (NOT USED)

```{r}
#Initialize an empty list to store subsets of the dataframe
dataframe_subsets <- vector("list", 25)  # Assuming you want subsets for numbers 1 to 25

#Group columns by their endings
for (test in 1:25) {
  cols <- grep(paste0("\\D", test, "$"), names(functional_darwin))
  dataframe_subsets[[test]] <- functional_darwin[, cols, drop = FALSE]
}

dataframe_subsets[[1]]
```

```{r}
#fit <- bestBIC(darwin_Y ~ ., data = drop_darwin_x, family = "binomial")
#summary(fit)
#coef(fit) #MLE under top model
#confint(fit) #conf int under top model
```

Is invertibility of X^t possible in the original darwin_x possible?

```{r}
#solve.default(t(as.matrix(drop_darwin_x)) %*% as.matrix(drop_darwin_x))
```


## Regression

### Performance metrics 

mcfadden_pseudo_r2

```{r}
mcfadden_pseudo_r2 <- function(pred_model,pred_0, y){
  loglike_model <- sum(y*log(pred_model)+(1-y)*log(1-pred_model), na.rm = TRUE)
  loglike_0 <- sum(y*log(pred_0)+(1-y)*log(1-pred_0), na.rm = TRUE)
  return(1-loglike_model/loglike_0)
}
```

FNR

```{r}
FNR <- function(proba.pred, truth){
  class.pred <- as.numeric(proba.pred > 0.5)
  conf <- table(truth, class.pred)
  FNR <- conf[2, 1] / sum(conf[2, 1], conf[2, 2])
  return(FNR)
}
```


### LASSO-CV (Via cross-validation)

#### Fitting the model

```{r}
kfoldCV.lasso.logistic <- function(y,x,K=10,seed,criterion='cv') {
## Perform K-fold cross-validation for LASSO regression estimate (lambda set either via cross-val or BIC or EBIC)
## Input
## - y: response
## - x: data.frame with predictors, intercept should not be present
## - K: number of folds in K-fold cross-validation
## - seed: random number generator seed (optional)
## - criterion: the criterion to select the penalization parameter, either cross-val or BIC or EBIC
## Output
## - pred: cross-validated predictions for y
## - ssr: residual sum of squares, sum((y-pred)^2)
  require(glmnet)
  if (!missing(seed)) set.seed(seed)
  subset <- rep(1:K,ceiling(nrow(x)/K))[1:nrow(x)]
  subset <- sample(subset,size=nrow(x),replace=FALSE)
  pred <- double(nrow(x))
  pred_0 <- double(nrow(x))
  cat("Starting cross-validation")
  if (ncol(x)>0) {  #if there are some covariates
    for (k in 1:K) {
        sel <- subset==k
        pred_0[sel] <- mean(y[!sel])
        if (criterion=='cv') {
            fit <- cv.glmnet(x=x[!sel,,drop=FALSE], y=y[!sel], alpha = 1, nfolds=10, family = 'binomial')
            pred[sel] <- predict(fit,newx=x[sel,,drop=FALSE],type='response', s='lambda.min')
        } else if (criterion=='bic'){
            fit <- lasso.bic.logistic(y=y[!sel],x=x[!sel,,drop=FALSE])
            pred[sel] <- predict(fit$model,newx=x[sel,,drop=FALSE],type='response', s = fit$lambda.opt)
        } else if (criterion=='ebic'){
            fit <- lasso.bic.logistic(y=y[!sel],x=x[!sel,,drop=FALSE],extended = TRUE)
            pred[sel] <- predict(fit$model,newx=x[sel,,drop=FALSE],type='response', s = fit$lambda.opt)
        } else { stop("method.lambda not implemented") }
        cat(".")
    }
  } else { #if there are no covariates, just use the intercept
    for (k in 1:K) {
      sel <- subset==k
      pred[sel] <- mean(y[!sel],na.rm=TRUE)
    }
  }
  cat("\n")
  return(list(pred=pred, pred_0= pred_0,ssr=sum((pred-y)^2,na.rm=TRUE)))
}
```


```{r}
set.seed(1234)
t0 <- Sys.time()
fit.lassocv <- cv.glmnet(x=as.matrix(functional_darwin),y=darwin_Y,family ='binomial', nfolds = 10, aplha = 1)
t1 <- Sys.time()
cat('\nTime elapsed: ')
```


```{r}
print(round(t1-t0,3))
```

```{r}
fit.lassocv
```

```{r}
plot(fit.lassocv) 
```

```{r}
b.lassocv = as.vector(coef(fit.lassocv, s='lambda.min'))
sum(b.lassocv[-1] != 0)
```

```{r}
rownames(coef(fit.lassocv, s = 'lambda.min'))[coef(fit.lassocv, s = 'lambda.min')[,1]!= 0]
```
```{r}
colnames(as.matrix(functional_darwin[,b.lassocv!=0]))
```


#### Model performance

We get the in-sample auc for the LASSO-CV model:
```{r}
lassocv.pred<- predict(fit.lassocv, newx=as.matrix(functional_darwin), s = fit.lassocv$lambda.min) # NEEDS TO BE FIXED
(auc.lassoCV.training<- pROC::auc(darwin_Y,lassocv.pred))
```

Out-sample prediction 

```{r}
cv.pred.lasso.cv <- kfoldCV.lasso.logistic(y=darwin_Y,x=as.matrix(functional_darwin),K=10,seed=1,criterion="cv")
```


```{r}
(auc.lassocv.test<- pROC::auc(darwin_Y,cv.pred.lasso.cv$pred))
```

```{r}
FNR(cv.pred.lasso.cv$pred,darwin_Y)
```

```{r}
mcfadden_pseudo_r2(cv.pred.lasso.cv$pred,cv.pred.lasso.cv$pred_0, darwin_Y)
```



### RIDGE

#### Fitting the model

```{r}
kfoldCV.ridge <- function(y,x,K=10,seed,criterion='cv') {
  ## Perform K-fold cross-validation for Ridge regression estimate (lambda set via cross-val)
  ## Input
  ## - y: response
  ## - x: data.frame with predictors, intercept should not be present
  ## - K: number of folds in K-fold cross-validation
  ## - seed: random number generator seed (optional)
  ## - criterion: the criterion to select the penalization parameter, (only cross-val for now)
  ## Output
  ## - pred: cross-validated predictions for y
  ## - ssr: residual sum of squares, sum((y-pred)^2)
  require(glmnet)
  if (!missing(seed)) set.seed(seed)
  subset <- rep(1:K,ceiling(nrow(x)/K))[1:nrow(x)]
  subset <- sample(subset,size=nrow(x),replace=FALSE)
  pred <- double(nrow(x))
  cat("Starting cross-validation")
  if (ncol(x)>0) {  #if there are some covariates
    for (k in 1:K) {
      sel <- subset==k
      if (criterion=='cv') {
        fit <- cv.glmnet(x=x[!sel,,drop=FALSE], y=y[!sel], alpha = 0, nfolds=10, family = 'binomial')
        b= as.vector(coef(fit,s='lambda.min'))
        pred[sel] <- b[1] + x[sel,,drop=FALSE] %*% as.matrix(b[-1])
      } else { stop("method.lambda not implemented") }
      cat(".")
    }
  } else { #if there are no covariates, just use the intercept
    for (k in 1:K) {
      sel <- subset==k
      pred[sel] <- mean(y[!sel],na.rm=TRUE)
    }
  }
  cat("\n")
  return(list(pred=pred,ssr=sum((pred-y)^2,na.rm=TRUE)))
}


```


```{r}
fit.ridge= cv.glmnet(x=as.matrix(functional_darwin), y=darwin_Y,family ='binomial', alpha = 0, nfolds=10)
fit.ridge
```

```{r}
b.rigde <- as.vector(coef(fit.ridge, s='lambda.min'))
names(b.rigde) <- c('intercept',colnames(functional_darwin))
sum(b.rigde[-1]!=0)
```

#### Model performance

In-sample predictions

```{r}

```


Out-sample prediction
```{r}
cv.ridge= kfoldCV.ridge(x=as.matrix(functional_darwin), y=darwin_Y,K=10,seed=1,criterion="cv")
```

```{r}
(auc.ridge.test<- pROC::auc(darwin_Y,cv.ridge$pred))
```

```{r}
FNR(cv.ridge$pred,darwin_Y)
```

```{r}
#mcfadden_pseudo_r2(cv.ridge$pred,cv.ridge$pred, darwin_Y)
```




### LASSO-BIC (Via BIC)

#### Fitting the model

Now the $\lambda$ is set via BIC using the function `lasso.bic` from `routines_seminar1.R`.

```{r}
lasso.bic.logistic <- function(y,x,extended=FALSE) {
  #Select model in LASSO path with best BIC (using LASSO regression estimates)
  #Input
  # - y: vector with response variable
  # - x: design matrix
  #
  #Output: list with the following elements
  # - coef: LASSO-estimated regression coefficient with lambda set via BIC
  # - ypred: predicted y
  # - lambda.opt: optimal value of lambda
  # - lambda: data.frame with bic and number of selected variables for each value of lambda
  require(glmnet)
  fit <- glmnet(x=x,y=y,family='binomial',alpha=1)
  pred <- predict(fit,newx=x,type='response')
  n <- length(y)
  p <- colSums(fit$beta!=0) + 1
  if (!extended){
    bic <- -2* colSums(y*log(pred)+(1-y)*log(1-pred)) + log(n)*p 
  } else {
    bic <- -2* colSums(y*log(pred)+(1-y)*log(1-pred)) + log(n)*p + 2*log(choose(ncol(x),p))
  }
  sel <- which.min(bic)
  beta <- c(fit$a0[sel],fit$beta[,sel]); names(beta)[1]= 'Intercept'
  ypred <- pred[,sel]
  ans <- list(model=fit,coef=beta,ypred=ypred,lambda.opt=fit$lambda[sel],lambda=data.frame(lambda=fit$lambda,bic=bic,nvars=p))
  return(ans)
}
```

To use the BIC criteria, the parameter `extended` is set to `FALSE`.

```{r}
fit.lassobic = lasso.bic.logistic(x = as.matrix(functional_darwin), y = darwin_Y, extended = FALSE)
b.lassobic = fit.lassobic$coef
names(fit.lassobic)
#round(b.lassobic, 3)
```

The number of non-zero coefficients for LASSO-BIC corresponds to:

```{r}
sum(b.lassobic[-1] != 0)
````



#### Model performance

We get the in-sample auc for the LASSO-BIC model:
```{r}
(auc.lassoBIC.training<- pROC::auc(darwin_Y,fit.lassobic$ypred))
```

```{r}
cv.pred.lasso.bic <- kfoldCV.lasso.logistic(y=darwin_Y,x=as.matrix(drop_darwin_x),K=10,seed=1,criterion="bic")

```

```{r}
(auc.lassoBIC.crossvalidated <- pROC::auc(darwin_Y,cv.pred.lasso.bic$pred))
```

```{r}
FNR(cv.pred.lasso.bic$pred,darwin_Y)
```

```{r}
mcfadden_pseudo_r2(cv.pred.lasso.bic$pred,cv.pred.lasso.bic$pred_0, darwin_Y)
```




### Bayes


```{r}
system.time(fit.bayesreg <- modelSelection(darwin_Y ~.,data = data.frame(functional_darwin), priorCoef=groupzellnerprior(tau=1), family = "binomial", priorGroup= groupzellnerprior(taustd=1), niter = 8000), priorDelta=modelbbprior(1,1)) #BMA with Laplace approx for marginal likelihood, MCMC for parameters




```

*Convergence checks:*

Convergence should be checked. The plot below corresponds to the trace of the number of variables selected at each MCMC iteration:

```{r}
margppest= matrix(NA,nrow=nrow(fit.bayesreg$postSample),ncol=ncol(fit.bayesreg$postSample))
for (j in 1:ncol(fit.bayesreg$postSample)) {
    margppest[,j]= cumsum(fit.bayesreg$postSample[,j])/(1:nrow(fit.bayesreg$postSample))
}

par(mar=c(4,5,.1,.1), cex.lab=1, cex.axis=1)
plot(margppest[,1], type='l', ylim=c(0,1), xlab='Gibbs iteration', ylab='Estimated P(gamma_j=1 | y)')
for (j in 2:ncol(margppest)) lines(margppest[,j])
```

The most the probable models are:
```{r}
head(postProb(fit.bayesreg),10)
```




```{r}
ci.bayesreg <- coef(fit.bayesreg)[-c(1,nrow(coef(fit.bayesreg))),]
sel.bayesreg <- ci.bayesreg[,4] > 0.5
ci.bayesreg[,1:3] <- round(ci.bayesreg[,1:3], 3)  
ci.bayesreg[,4] <- round(ci.bayesreg[,4], 4)      
head(ci.bayesreg)
tail(ci.bayesreg)
```

```{r}
coef(fit.bayesreg)[order(coef(fit.bayesreg)[,4], decreasing = TRUE),]
```


